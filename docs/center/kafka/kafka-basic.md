# kafka简介

应用程序会产生很多数据，比如用户浏览偏好等，我们需要用这些数据去转化成商品推荐等更有价值的能力。不同于一般的介绍kafka起源的博客，《kafka权威指南》用**数据管道**的重要性来引入kafka，而不是领英的日志构建。书中把这种依靠数据做业务需求的系统称为数据驱动型应用，数据驱动型应用更加关注数据在系统中的全生命周期管理。

## 发布订阅模型

> Kafka 本质上就是一个**基于日志**的超大规模的发布-订阅系统

首先为什么要发布订阅模型，直接发送不行吗？

### 同步异步发送对比

#### 直接发送（同步）

比如：A 服务调用 B 服务接口

```text
A -> HTTP/RPC -> B -> 返回结果 -> A继续执行
```

这种数据传输方式很好调试，结果立即可得，适合比较登录这种流程。但是这种方式会有几个问题：

1. 耦合性强：A需要维护B的信息，比如地址、接口、参数以及是否存活等。
2. 服务雪崩：在高并发的场景下，中间一环失败会导致整个链路不可用。
3. 难以扩展：如果后续需要增加新的环节，之前的代码必须大改。



#### 发布订阅模型（异步）

发布订阅模型中的A不知道哪个服务会处理，也不会关心哪个服务会处理

```text
A 发布事件 -> MQ -> 多个消费者各自处理
```

举例：

```
           审核服务
发帖 -> MQ  推荐服务
           AI分析
           埋点统计
           通知服务
```



> [!TIP] 常见八股：为什么要用消息队列
>
> 1. 解耦：生产者只负责“发生了什么”，不负责“谁处理”。
> 2. 削峰填谷（抗高并发）：假设瞬间 10w 请求，直接调用可能数据库受不了，但是用消息队列系统不会崩，只是延迟增加。
> 3. 异步：提升响应速度。



### 发布订阅系统演进

来看一个场景，顺便发明一下kafka。

假设你的需求是把用户行为日志数据交给搜推系统进行构建，你就可以直接发送数据；后续你又发现，大盘指标系统也需要用户行为数据，于是你默默扩展了接收方。这时候还只是1-2的关系，不是太复杂。随着业务的进一步复杂化，你有数仓的数据需要构建，你有爬虫系统的数据需要构建，你有用户聊天数据需要构建——当系统变成n-m的关系的时候，系统已经债台高筑了（技术债）。

当你和你的同时进行梳理的时候，你们会发现这种需求很普遍，所以抽出一个独立的队列系统，再应用我们刚刚说的异步思想去解耦。恭喜你们，你们成功发明了kafka～

<img src="https://imgtu.oss-cn-beijing.aliyuncs.com/image/image-20260215101852094.png" alt="image-20260215101852094" style="zoom: 50%;" />

到这一步比点对点系统好得多，但是根据业务扩展的时候又会造成重复，所以我们需要的是一个集中式的系统，可以根据业务去做扩展。



## kafka基础知识

Kafka就是为了解决上述问题而设计的一款**基于发布与订阅模式**的消息系统。文件系统或数据库提交日志旨在保存事务的持久化记录，通过**重放**这些日志可以重建系统状态。同样，Kafka的数据是按照一定的**顺序持久化**保存的，并且可以按需读取。此外，Kafka的数据分布在整个系统中，具备数据故障恢复能力和性能伸缩能力。

#### 消息和批次

Kafka 中的基本数据单位是**消息**，可以类比为数据库的一行记录，本质是一个字节数组，Kafka 不关心其具体格式。
消息可以包含一个可选的**键**，用于决定消息写入哪个分区：通常对键做哈希并对分区数取模，从而保证相同键的消息进入同一分区（只要分区数不变）。
为了提升吞吐与网络效率，Kafka 不会逐条发送消息，而是把属于同一主题和分区的多条消息**批量打包后再写入和传输**。

#### 模式

Kafka 本身不理解消息内容，消息只是字节数组，因此通常需要通过模式来定义数据结构以便解析和维护。

 JSON、XML 等格式易读易用，但缺乏强类型和良好的版本兼容能力；而 Avro 提供紧凑的序列化格式，并将模式与数据分离，支持强类型与模式演化（向前/向后兼容），无需频繁修改代码。

 统一的数据格式能降低生产者与消费者之间的耦合，使系统在数据结构升级时仍能兼容新旧消息版本。

#### 主题和分区*

Kafka 使用 Topic（主题） 对消息进行逻辑分类，而数据实际存储在 Partition（分区） 中。每个分区是一个只能追加写入的日志，消息按写入顺序（FIFO）读取，因此 只保证分区内有序，不保证整个主题全局有序。
通过将分区分布到多台服务器并对其进行副本复制，Kafka 同时实现了 横向扩展能力（高性能）和容错能力（高可用）。

下面是摘自《kafka权威指南》的原图：

![image-20260215103256547](https://imgtu.oss-cn-beijing.aliyuncs.com/image/image-20260215103256547.png)



#### 生产者和消费者

##### 生产者

生产者负责**创建并发送消息到指定 Topic**，默认将消息**均匀分布到 Topic 的所有分区（负载均衡）**。

> 但在很多业务中需要“同一类数据有序”，因此消息可以带 key，分区器（Partitioner）会对 key 做 **哈希计算 → 映射到固定分区**，从而保证 相同 key 的消息一定进入同一个分区 ，从而保证顺序消费

##### 消费者

负责从 Topic 读取消息，通常以 **消费者组** 方式工作，属于同一群组的一个或多个消费者共同读取一个主题。kafka 并不是“推送”，而是消费者主动拉消息。每个分区同一时刻只会被一个消费者消费 ，保证分区内顺序。

#### broker和集群

Kafka 的 broker 是单台服务器，负责接收生产者消息、分配偏移量、持久化到磁盘并响应消费者请求。多个 broker 组成集群，其中一个自动选举的 broker 担任控制器（Controller），负责分区分配、Leader 选举和故障恢复。每个分区有一个 Leader 和多个 Follower 副本，生产者只能写入 Leader，消费者可从 Leader 或 Follower 读取。分区复制保证高可用性，当 Leader 宕机时，Follower 可接管。Kafka 的消息有保留策略，可按时间或大小删除旧消息，也可配置紧凑型日志，仅保留每个键的最新消息。