# 1亿玩家实时战绩排名方案

>  学而习之：https://mp.weixin.qq.com/s/ZhVULR3esu66ZrMVaCEm2g?scene=1

## 美中不足的方案

### redis zset分桶

把玩家按分数每 1000 分切一个 ZSet，避免 BigKey，查排名时累加各桶人数。

但是这个方案有三个问题解决不了：

1. 中间往往集中了大部分的玩家，中间桶压力过大
2. redis cluster模式下，lua脚本无法跨节点执行
3. 同分怎么处理



## 方案设计需要考虑的重点

### 数据量大

处理大数据，第一都会想到分批去处理。再根据需要排序，所以自然而然想到分桶+zset。但这种做法忽略了数据的分布特性——在许多实际场景中，用户产生的数据往往更接近正态分布。比如段位相关的游戏数据分布可能如下：

<img src="https://imgtu.oss-cn-beijing.aliyuncs.com/image/image-20260217231428312.png" alt="image-20260217231428312" style="zoom:50%;" />

如果按固定分数分桶，那中间位的桶可能会有大部分的数据，**BigKey 问题压根没解决，Redis 单线程操作依然卡死，且集群数据严重倾斜，一个节点忙死，其他节点闲死**。



### 排序

这个需求的另一个重点在于排序。如何实时更新1亿人的排名呢？如果2000万人在线，每秒对每个用户结算，那redis肯定撑不住。所以这个优化方案的核心就是：只保证前面1000人的排位绝对准确，因为前面那顶尖的一批更会关心自己的准确排名，而中间的一部分排名近似估算。

<img src="https://imgtu.oss-cn-beijing.aliyuncs.com/image/image-20260217232209861.png" alt="image-20260217232209861" style="zoom:50%;" />



## 最终方案

**分层架构**：

- **头部玩家（Top 5000）**：使用 ZSet 存储。**数据冗余设计**，避免排名变动时的跨数据结构事务问题。
  - Top5000 不需要全量遍历 1 亿玩家，核心是增量触发 + ZSet 自动筛选：只有当玩家分数发生变动，且分数达到当前 ZSet 的准入区间时，才会执行 ZADD 操作
- **腰部玩家**：使用 **Redis Hash 计数器**。为了解决单点热点写，我采用了 **Sharding 策略**（拆分 16 个 Key 随机写）。
- **尾部**玩家：不活跃用户，异步落库 ClickHouse，不做实时排名。



